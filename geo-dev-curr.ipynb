{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142568,"status":"ok","timestamp":1745236904420,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"gzSrVcg8W_wy","outputId":"7ce31d61-62ef-49c9-aaef-ebaf0a2c17f6"},"outputs":[{"data":{"text/plain":["\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\""]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torchvision.transforms as T\n","import matplotlib.pyplot as plt\n","import torchvision.models as models\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","from torchvision.transforms import functional as TF\n","from scipy.ndimage import gaussian_filter\n","import random\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassJaccardIndex, MulticlassStatScores\n","from collections import Counter\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\"\"\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1745236904422,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"Em_SBnsKEXCy"},"outputs":[],"source":["def plot_label_distribution(dataset):\n","    label_counts = Counter()\n","    for _, mask in dataset:\n","        labels, counts = np.unique(mask.numpy(), return_counts=True)\n","        label_counts.update(dict(zip(labels, counts)))\n","\n","    # Sorting by class index\n","    sorted_labels = sorted(label_counts.keys())\n","    counts = [label_counts[l] for l in sorted_labels]\n","\n","    plt.figure(figsize=(8, 5))\n","    plt.bar(sorted_labels, counts, tick_label=[f'Class {i}' for i in sorted_labels])\n","    plt.xlabel('Class')\n","    plt.ylabel('Pixel Count')\n","    plt.title('Label Distribution (Pixel-wise)')\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1745236904425,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"omFl6_NnnHBy"},"outputs":[],"source":["\"\"\"class LandUseDataset(torch.utils.data.Dataset):\n","    def __init__(self, path, transform=None):\n","        data = np.load(path)\n","        self.X = np.clip(data['X'] / 10000.0, 0.0, 1.0)   # Shape: (N, C=13, H, W)\n","        self.y = data['y']   # Shape: (N, H, W)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        X = torch.tensor(self.X[idx], dtype=torch.float32)  # (C=13, H, W)\n","        y = torch.tensor(self.y[idx], dtype=torch.long)     # (H, W)\n","\n","        if self.transform:\n","            X = self.transform(X)\n","\n","        return X, y\n","\"\"\"\n","\n","class LandUseDataset(torch.utils.data.Dataset):\n","    def __init__(self, path, transform=None):\n","        data = np.load(path)\n","        self.X = np.clip(data['X'] / 10000.0, 0.0, 1.0)   # Shape: (N, C=13, H, W)\n","        self.y = self._remap_labels(data['y'])            # Shape: (N, H, W)\n","        self.transform = transform\n","\n","    def _remap_labels(self, y):\n","        id2idx = {10: 0, 20: 1, 30: 2, 40: 3, 50: 4, 60: 5, 80: 6, 90: 7}\n","        y_remapped = np.copy(y)\n","        for old, new in id2idx.items():\n","            y_remapped[y == old] = new\n","        return y_remapped\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        X = torch.tensor(self.X[idx], dtype=torch.float32)  # (C=13, H, W)\n","        y = torch.tensor(self.y[idx], dtype=torch.long)     # (H, W)\n","\n","        if self.transform:\n","            X = self.transform(X)\n","\n","        return X, y"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1745236904456,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"OOH0hh_UXF6w"},"outputs":[],"source":["class UNetResNet18(nn.Module):\n","    def __init__(self, num_classes, input_channels=13):\n","        super(UNetResNet18, self).__init__()\n","\n","        # Load pretrained ResNet18\n","        resnet = models.resnet18(pretrained=True)\n","\n","        # Override the first conv layer to accept 13 input channels\n","        self.encoder_conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.encoder_bn1 = resnet.bn1\n","        self.encoder_relu = resnet.relu\n","        self.encoder_maxpool = resnet.maxpool\n","\n","        # ResNet layers\n","        self.encoder_layer1 = resnet.layer1  # 64 -> 64\n","        self.encoder_layer2 = resnet.layer2  # 64 -> 128\n","        self.encoder_layer3 = resnet.layer3  # 128 -> 256\n","        self.encoder_layer4 = resnet.layer4  # 256 -> 512\n","\n","        # Decoder part (upsampling + skip connections)\n","        self.upconv4 = self._upsample(512, 256)\n","        self.upconv3 = self._upsample(256 + 256, 128)  # skip conn\n","        self.upconv2 = self._upsample(128 + 128, 64)   # skip conn\n","        self.upconv1 = self._upsample(64 + 64, 64)\n","\n","        # Final classifier\n","        self.classifier = nn.Conv2d(64, num_classes, kernel_size=1)\n","\n","    def _upsample(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","    def forward(self, x):\n","        # Encoder\n","        x1 = self.encoder_relu(self.encoder_bn1(self.encoder_conv1(x)))  # [B, 64, H/2, W/2]\n","        x2 = self.encoder_layer1(self.encoder_maxpool(x1))               # [B, 64, H/4, W/4]\n","        x3 = self.encoder_layer2(x2)                                     # [B, 128, H/8, W/8]\n","        x4 = self.encoder_layer3(x3)                                     # [B, 256, H/16, W/16]\n","        x5 = self.encoder_layer4(x4)                                     # [B, 512, H/32, W/32]\n","\n","        # Decoder with U-Net style skip connections (at least 2 used: x4, x3)\n","        d4 = self.upconv4(x5)                    # [B, 256, H/16, W/16]\n","        d4 = torch.cat([d4, x4], dim=1)          # skip conn 1\n","\n","        d3 = self.upconv3(d4)                    # [B, 128, H/8, W/8]\n","        d3 = torch.cat([d3, x3], dim=1)          # skip conn 2\n","\n","        d2 = self.upconv2(d3)                    # [B, 64, H/4, W/4]\n","        d2 = torch.cat([d2, x2], dim=1)          # optional skip\n","\n","        d1 = self.upconv1(d2)                    # [B, 64, H/2, W/2]\n","\n","        out = F.interpolate(d1, scale_factor=2, mode='bilinear', align_corners=False)\n","        out = self.classifier(out)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1745236904458,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"JxH0X3jPu7Nb"},"outputs":[],"source":["class UNetResNet50(nn.Module):\n","    def __init__(self, num_classes, input_channels=13):\n","        super(UNetResNet50, self).__init__()\n","\n","        # Load pretrained ResNet-50\n","        resnet = models.resnet50(pretrained=True)\n","\n","        # Replace the first conv layer to accept 13 input channels\n","        self.encoder_conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.encoder_bn1 = resnet.bn1\n","        self.encoder_relu = resnet.relu\n","        self.encoder_maxpool = resnet.maxpool\n","\n","        # ResNet-50 layers\n","        self.encoder_layer1 = resnet.layer1  # 256\n","        self.encoder_layer2 = resnet.layer2  # 512\n","        self.encoder_layer3 = resnet.layer3  # 1024\n","        self.encoder_layer4 = resnet.layer4  # 2048\n","\n","        # Decoder\n","        self.upconv4 = self._upsample(2048, 1024)\n","        self.upconv3 = self._upsample(1024 + 1024, 512)\n","        self.upconv2 = self._upsample(512 + 512, 256)\n","        self.upconv1 = self._upsample(256 + 256, 64)\n","\n","        self.classifier = nn.Conv2d(64, num_classes, kernel_size=1)\n","\n","    def _upsample(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","    def forward(self, x):\n","        # Encoder\n","        x1 = self.encoder_relu(self.encoder_bn1(self.encoder_conv1(x)))  # [B, 64, H/2, W/2]\n","        x2 = self.encoder_layer1(self.encoder_maxpool(x1))               # [B, 256, H/4, W/4]\n","        x3 = self.encoder_layer2(x2)                                     # [B, 512, H/8, W/8]\n","        x4 = self.encoder_layer3(x3)                                     # [B, 1024, H/16, W/16]\n","        x5 = self.encoder_layer4(x4)                                     # [B, 2048, H/32, W/32]\n","\n","        # Decoder with skip connections\n","        d4 = self.upconv4(x5)                    # [B, 1024, H/16, W/16]\n","        d4 = torch.cat([d4, x4], dim=1)\n","\n","        d3 = self.upconv3(d4)                    # [B, 512, H/8, W/8]\n","        d3 = torch.cat([d3, x3], dim=1)\n","\n","        d2 = self.upconv2(d3)                    # [B, 256, H/4, W/4]\n","        d2 = torch.cat([d2, x2], dim=1)\n","\n","        d1 = self.upconv1(d2)                    # [B, 64, H/2, W/2]\n","\n","        out = F.interpolate(d1, scale_factor=2, mode='bilinear', align_corners=False)\n","        out = self.classifier(out)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1745236904460,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"JCEcoafTrs9H"},"outputs":[],"source":["def train_one_epoch(model, optimizer, train_dl, device, criterion):\n","    model.train()\n","    curr_loss = 0.\n","    for X, y in train_dl:\n","        X, y = X.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        logits = model(X)\n","        loss = criterion(logits, y)\n","        loss.backward()\n","        optimizer.step()\n","        curr_loss += loss.item()\n","    return curr_loss / len(train_dl)\n","\n","\"\"\"def validate(model, val_dl, device, criterion):\n","    model.eval()\n","    curr_loss = 0.\n","    with torch.inference_mode():\n","        for X, y in val_dl:\n","            X, y = X.to(device), y.to(device)\n","            logits = model(X)\n","            loss = criterion(logits, y)\n","            curr_loss += loss.item()\n","    return curr_loss / len(val_dl)\"\"\"\n","\n","def validate(model, val_dl, device, criterion, num_classes):\n","    model.eval()\n","    curr_loss = 0.\n","\n","    # Metrics\n","    pixel_acc = MulticlassAccuracy(num_classes=num_classes, average='micro').to(device)\n","    iou = MulticlassJaccardIndex(num_classes=num_classes, average=None).to(device)  # per-class IoU\n","    mean_iou = MulticlassJaccardIndex(num_classes=num_classes, average='macro').to(device)  # mean IoU\n","    stat_scores = MulticlassStatScores(num_classes=num_classes, average=None).to(device)\n","    stat_scores.reset()\n","    pixel_acc.reset()\n","    iou.reset()\n","    mean_iou.reset()\n","\n","    with torch.inference_mode():\n","        for X, y in val_dl:\n","            X, y = X.to(device), y.to(device)\n","\n","            logits = model(X)  # shape: [B, C, H, W]\n","            loss = criterion(logits, y)\n","            curr_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=1)  # shape: [B, H, W]\n","\n","            preds_flat = preds.flatten()\n","            y_flat = y.flatten()\n","\n","            # Update metrics\n","            pixel_acc.update(preds_flat, y_flat)\n","            iou.update(preds_flat, y_flat)\n","            mean_iou.update(preds_flat, y_flat)\n","            stat_scores.update(preds_flat, y_flat)\n","\n","\n","    # Compute final metric values\n","    avg_loss = curr_loss / len(val_dl)\n","    pixel_accuracy = pixel_acc.compute().item()\n","    per_class_iou = iou.compute().cpu().numpy()  # shape: [num_classes]\n","    mean_iou_val = mean_iou.compute().item()\n","    stat_result = stat_scores.compute()  # shape: [num_classes, 4]\n","    per_class_support = stat_result[:, 0] + stat_result[:, 2]  # TP + FN\n","    # Normalize support to get weights\n","    weights = per_class_support.float() / per_class_support.sum()\n","    # Compute weighted mean IoU\n","    weighted_mean_iou = (weights * torch.tensor(per_class_iou).to(device)).sum().item()\n","\n","    return {\n","        \"val_loss\": avg_loss,\n","        \"pixel_accuracy\": pixel_accuracy,\n","        \"mean_iou\": mean_iou_val,\n","        \"per_class_iou\": per_class_iou,\n","        \"weighted_mean_iou\": weighted_mean_iou\n","    }\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":95,"status":"ok","timestamp":1745236904558,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"2XVR6oiX1W48"},"outputs":[],"source":["class RandomApplyTransform:\n","    def __init__(self, transform, p=0.5):\n","        self.transform = transform\n","        self.p = p\n","\n","    def __call__(self, x):\n","        if random.random() < self.p:\n","            return self.transform(x)\n","        return x\n","\n","class RandomRotationTensor:\n","    def __init__(self, degrees=15):\n","        self.degrees = degrees\n","\n","    def __call__(self, x):\n","        angle = random.uniform(-self.degrees, self.degrees)\n","        return TF.rotate(x, angle)\n","\n","class RandomRadiometricShift:\n","    def __init__(self, scale=0.05):\n","        self.scale = scale\n","\n","    def __call__(self, x):\n","        shift = torch.empty_like(x).uniform_(-self.scale, self.scale)\n","        return x + shift\n","\n","class RandomGaussianBlur:\n","    def __init__(self, sigma_range=(0.5, 1.0)):\n","        self.sigma_range = sigma_range\n","\n","    def __call__(self, x):\n","        sigma = random.uniform(*self.sigma_range)\n","        x_np = x.numpy()\n","        x_np = gaussian_filter(x_np, sigma=(0, 1, 1))  # blur spatial dims\n","        return torch.from_numpy(x_np)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1745236904588,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"0DCd_WWP2_p1"},"outputs":[],"source":["def get_dataloaders(path, batch_size=16, train_split=0.7, val_split=0.15, test_split=0.15, seed=42):\n","    \"\"\"\n","    Creates and returns dataloaders for training, validation, and testing.\n","\n","    Args:\n","        path (str): Path to the .npz file containing the dataset\n","        batch_size (int): Batch size for the dataloaders\n","        train_split (float): Proportion of data to use for training\n","        val_split (float): Proportion of data to use for validation\n","        test_split (float): Proportion of data to use for testing\n","        seed (int): Random seed for reproducibility\n","\n","    Returns:\n","        tuple: (dataset, train_loader, val_loader, test_loader)\n","    \"\"\"\n","    # Define transforms for training\n","    train_transform = T.Compose([\n","        T.RandomHorizontalFlip(p=0.4),\n","        #RandomApplyTransform(RandomRotationTensor(degrees=15), p=0.5),\n","        RandomApplyTransform(RandomRadiometricShift(scale=0.05), p=0.4),\n","        #RandomApplyTransform(RandomGaussianBlur(), p=0.2)\n","    ])\n","\n","    # Create a single dataset instance\n","    dataset = LandUseDataset(path)\n","\n","    # Split indices manually for reproducibility\n","    total_size = len(dataset)\n","    train_size = int(train_split * total_size)\n","\n","    indices = list(range(total_size))\n","    random.seed(seed)\n","    random.shuffle(indices)\n","\n","    train_indices = indices[:train_size]\n","    val_indices = indices[train_size:]\n","\n","    # Create custom dataset wrappers that apply transforms on-the-fly\n","    class TransformSubset(torch.utils.data.Dataset):\n","        def __init__(self, dataset, indices, transform=None):\n","            self.dataset = dataset\n","            self.indices = indices\n","            self.transform = transform\n","\n","        def __len__(self):\n","            return len(self.indices)\n","\n","        def __getitem__(self, idx):\n","            X, y = self.dataset[self.indices[idx]]\n","            if self.transform:\n","                X = self.transform(X)\n","            return X, y\n","\n","    # Create subsets with appropriate transforms\n","    train_ds = TransformSubset(dataset, train_indices, transform=train_transform)\n","    val_ds = TransformSubset(dataset, val_indices, transform=None)\n","\n","    # Create dataloaders\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","    return dataset, train_loader, val_loader"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":26325,"status":"ok","timestamp":1745236930929,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"f92B0KY13MO-","outputId":"8e9efb77-f8cc-4172-8420-cb0737703461"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique labels in masks: [0 1 2 3 4 5 6 7]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#dataset, train_loader, val_loader = get_dataloaders(\"/content/drive/MyDrive/image_label_dataset.npz\")\n","#dataset, train_loader, val_loader = get_dataloaders(\"/content/drive/MyDrive/generated_dataset.npz\")\n","dataset, train_loader, val_loader = get_dataloaders(\"generated_dataset.npz\")\n","num_classes = len(np.unique(dataset.y))\n","print(\"Unique labels in masks:\", np.unique(dataset.y))\n","plot_label_distribution(dataset)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1745236930943,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"BjPdTvTe00UV","outputId":"e1e8e28d-8428-42e2-de99-1943d36215e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda\n"]}],"source":["# Model setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1745236931166,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"UyIWIRd2NhTW"},"outputs":[],"source":["def train_model(model, num_epochs, device, train_loader, val_loader, num_classes, learning_rate):\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n","    model.to(device)\n","\n","    best_val_loss = 10000.\n","    metrics = {\"train_losses\": [], \"val_losses\": [], \"pixel_accs\": [], \"mean_ious\": [], \"per_class_ious\": [], \"weighted_ious\": []}\n","    for epoch in range(num_epochs):\n","        avg_train_loss = train_one_epoch(model, optimizer, train_loader, device, criterion)\n","        val_metrics = validate(model, val_loader, device, criterion, num_classes)\n","        print(f\"\\nEpoch {epoch + 1}\")\n","        print(f\"Average Training Loss {avg_train_loss}\")\n","        for metric, value in val_metrics.items():\n","            print(f\"{metric}: {value}\")\n","        scheduler.step(val_metrics[\"val_loss\"])\n","\n","        if val_metrics[\"val_loss\"] < best_val_loss:\n","            best_val_loss = val_metrics[\"val_loss\"]\n","            torch.save(model.state_dict(), f\"best_model_lr_{learning_rate}.pt\")\n","            print(\"Saved new best model.\")\n","\n","        metrics[\"train_losses\"].append(avg_train_loss)\n","        metrics[\"val_losses\"].append(val_metrics[\"val_loss\"])\n","        metrics[\"pixel_accs\"].append(val_metrics[\"pixel_accuracy\"])\n","        metrics[\"mean_ious\"].append(val_metrics[\"mean_iou\"])\n","        metrics[\"per_class_ious\"].append(val_metrics[\"per_class_iou\"])\n","        metrics[\"weighted_ious\"].append(val_metrics[\"weighted_mean_iou\"])\n","\n","\n","    print(f\"\\nBest model was with(val loss = {best_val_loss:.4f})\")\n","    return metrics, best_val_loss\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":2337,"status":"error","timestamp":1745237227430,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"TrRBIEPlNlsE","outputId":"3f237e1a-08bd-4a17-85db-e1a047129174"},"outputs":[{"ename":"NameError","evalue":"name 'UNetResNet18' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-87a1b11e3fb2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'UNetResNet18' is not defined"]}],"source":["model = UNetResNet18(input_channels=13, num_classes=num_classes)\n","metrics, _ = train_model(model, 50, device, train_loader, val_loader, num_classes, learning_rate=0.0001)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"U2z9nGtXPe5U"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/alex/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/alex/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/alex/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:02<00:00, 37.6MB/s]\n","/home/alex/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1\n","Average Training Loss 1.1997914937409488\n","val_loss: 0.8258086560588134\n","pixel_accuracy: 0.7572780251502991\n","mean_iou: 0.31701070070266724\n","per_class_iou: [0.7100302  0.         0.40318972 0.43122652 0.         0.\n"," 0.99163926 0.        ]\n","Saved new best model.\n","\n","Epoch 2\n","Average Training Loss 0.8832721385088834\n","val_loss: 0.6952615599883231\n","pixel_accuracy: 0.780823290348053\n","mean_iou: 0.32200682163238525\n","per_class_iou: [0.77413034 0.         0.33632106 0.47271836 0.         0.\n"," 0.992885   0.        ]\n","Saved new best model.\n","\n","Epoch 3\n","Average Training Loss 0.78464034978639\n","val_loss: 0.6272250531535399\n","pixel_accuracy: 0.7928830981254578\n","mean_iou: 0.3268784284591675\n","per_class_iou: [0.76401025 0.         0.43602052 0.42296118 0.         0.\n"," 0.9920353  0.        ]\n","Saved new best model.\n","\n","Epoch 4\n","Average Training Loss 0.7527399330653928\n","val_loss: 0.5746113352085415\n","pixel_accuracy: 0.8165193796157837\n","mean_iou: 0.3496816158294678\n","per_class_iou: [7.8519267e-01 0.0000000e+00 4.7579324e-01 5.4589009e-01 3.3691039e-04\n"," 0.0000000e+00 9.9024016e-01 0.0000000e+00]\n","Saved new best model.\n","\n","Epoch 5\n","Average Training Loss 0.7408783848990094\n","val_loss: 0.6718484986769525\n","pixel_accuracy: 0.7889290452003479\n","mean_iou: 0.3297871947288513\n","per_class_iou: [0.77421856 0.         0.3733497  0.48351038 0.01747404 0.\n"," 0.989745   0.        ]\n","\n","Epoch 6\n","Average Training Loss 0.7498484978621657\n","val_loss: 0.5839656685528002\n","pixel_accuracy: 0.8159546852111816\n","mean_iou: 0.35024726390838623\n","per_class_iou: [7.84846187e-01 5.07876044e-03 4.48483914e-01 5.61073661e-01\n"," 1.21985115e-02 5.89622650e-04 9.89707232e-01 0.00000000e+00]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNetResNet50(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, device, train_loader, val_loader, num_classes, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_accs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_ious\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper_class_ious\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 10\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m validate(model, val_loader, device, criterion, num_classes)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, train_dl, device, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[6], line 37\u001b[0m, in \u001b[0;36mUNetResNet50.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_bn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))  \u001b[38;5;66;03m# [B, 64, H/2, W/2]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_maxpool(x1))               \u001b[38;5;66;03m# [B, 256, H/4, W/4]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer2(x2)                                     \u001b[38;5;66;03m# [B, 512, H/8, W/8]\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/pattrec1/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = UNetResNet50(input_channels=13, num_classes=num_classes)\n","\n","train_model(model, 50, device, train_loader, val_loader, num_classes, learning_rate=0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dC3YKTWqPe2b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1745089747784,"user":{"displayName":"Alex Filippakopoulos","userId":"14980402222045972637"},"user_tz":-180},"id":"M1gbT3iLxrti","outputId":"7f8dd7d1-c1c2-4a0b-8d9a-e71de79a18c9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'learning_rates = [1e-3, 5e-4, 1e-4]\\nbest_val_loss = float(\\'inf\\')\\nbest_model_state = None\\nbest_lr = None\\n\\nfor lr in learning_rates:\\n    print(f\"\\nRunning experiment with learning rate = {lr}\")\\n\\n    model = UNetResNet18(input_channels=13, num_classes=int(dataset.y.max()) + 1).to(device)\\n    optimizer = optim.Adam(model.parameters(), lr=lr)\\n    criterion = nn.CrossEntropyLoss()\\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\\'min\\', factor=0.5, patience=3, verbose=True)\\n\\n    num_epochs = 30\\n\\n    for epoch in range(num_epochs):\\n        train_loss = train_one_epoch(model, optimizer, train_loader, device, criterion)\\n        val_loss = validate(model, val_loader, device, criterion)\\n        print(f\"Epoch {epoch + 1}:\\n\\tAverage Training Loss: {train_loss:.4f}\\n\\tAverage Validation Loss: {val_loss:.4f}\")\\n        scheduler.step(val_loss)\\n\\n        if val_loss < best_val_loss:\\n            best_val_loss = val_loss\\n            best_lr = lr\\n            torch.save(model.state_dict(), \"best_model.pt\")\\n            print(\"Saved new best model.\")\\n\\nprint(f\"\\nBest model was with learning rate = {best_lr} (val loss = {best_val_loss:.4f})\")\\n'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"learning_rates = [1e-3, 5e-4, 1e-4]\n","best_val_losses = []\n","for lr in learning_rates:\n","    print(f\"\\nRunning experiment with initial learning rate = {lr}\")\n","    metrics, best_val_loss = train_model(model, num_epochs, device, train_loader, val_loader, num_classes, learning_rate)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgvoJCMwcG63"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPE3LKxPVWF20JWJ7duNlfA","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":0}
